{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae785c-bf88-45f7-bb14-4fb3e16f6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pylab as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from spacepy import pycdf\n",
    "import warnings\n",
    "import moms_fast\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "\n",
    "import nnet_evaluate\n",
    "import utils\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd00c1b-c9ae-438e-96f6-ccff2dfac875",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f076dd9-e714-4750-a7f3-fcfa079c48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf= h5py.File('/home/ubuntu/data/samples_train_n=50000_nosw.hdf')\n",
    "phases = list(hdf.keys())\n",
    "\n",
    "for phase in phases:\n",
    "    print(phase.ljust(20), hdf[phase]['E'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa285419-3b38-4aa4-a925-1ffed7cd0856",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6e0eb-7b88-4bae-862f-f52a8692e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "#    '/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/all.rfr001/moments_stats.hdf',\n",
    "    '/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4A_dusk_flank.rfr001/moments_stats.hdf',\n",
    "    '/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4B_dayside.rfr001/moments_stats.hdf',\n",
    "    '/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4C_dawn_flank.rfr001/moments_stats.hdf',\n",
    "    '/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4D_tail.rfr001/moments_stats.hdf',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c30ca-55c8-46e8-8995-ea8cdb25ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['n']\n",
    "for file_name in files:\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "    r2 = {m: hdf[m]['r2'][:] for m in moments}\n",
    "\n",
    "    print(os.path.basename(file_name), r2['n'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff327804-102d-4352-81d5-e540547ca305",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['vx', 'vy', 'vz']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex='all', sharey='all', figsize=(20, 6))\n",
    "\n",
    "for file_name in files:\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "    r2 = {m: hdf[m]['r2'][:] for m in moments}\n",
    "    points_true = {m: hdf[m]['points_true'][:] for m in moments}\n",
    "    points_recon = {m: hdf[m]['points_recon'][:] for m in moments}\n",
    "    hdf.close()\n",
    "    \n",
    "    region_title = 'Phase ' + os.path.basename(os.path.dirname(file_name)).replace(\"_\", \" \").split(\".\")[0]\n",
    "    region_title = ' '.join([word[0].upper() + word[1:] for word in region_title.split(' ')])\n",
    "\n",
    "    for i, m in enumerate(r2):\n",
    "        axes[i].plot(sizes/(32*16*2), r2[m], 'o-', label=region_title)\n",
    "        axes[i].set_title(m.capitalize())\n",
    "        axes[i].set_ylabel('Correlation Coefficient ($r^2$)', fontsize=12)\n",
    "        axes[i].set_xlabel('Dimensionality Reduction (Fraction)', fontsize=12)\n",
    "\n",
    "    axes[i].set_ylim(0.75, 1.05)\n",
    "for ax in axes:\n",
    "    ax.legend(ncol=2)\n",
    "    ax.axhline(1, color='black', linestyle='dashed')\n",
    "    \n",
    "fig.suptitle('Neural Network Bulk Velocity Reconstruction Correlation For Each Mission Phase', fontweight='bold', fontsize=20)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2574aa-7cbe-4f04-8649-e34ea92b2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['vx', 'vy', 'vz', 'n']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, sharex='all', sharey='all', figsize=(14, 4), dpi=300)\n",
    "\n",
    "for file_name in [files[1]]:\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "    r2 = {m: hdf[m]['r2'][:] for m in moments}\n",
    "    points_true = {m: hdf[m]['points_true'][:] for m in moments}\n",
    "    points_recon = {m: hdf[m]['points_recon'][:] for m in moments}\n",
    "    hdf.close()\n",
    "    \n",
    "    region_title = 'Phase ' + os.path.basename(os.path.dirname(file_name)).replace(\"_\", \" \").split(\".\")[0]\n",
    "    region_title = ' '.join([word[0].upper() + word[1:] for word in region_title.split(' ')])\n",
    "\n",
    "    for i, m in enumerate(r2):\n",
    "        axes[i].plot(sizes/(32*16*2), r2[m], 'o-')\n",
    "        \n",
    "        if m[0]== 'v':\n",
    "            axes[i].set_title('Flow Velocity ' + m[1].upper()) \n",
    "        else:\n",
    "            axes[i].set_title('Density') \n",
    "        axes[i].set_ylabel('Correlation Coefficient ($r^2$)', fontsize=12)\n",
    "        axes[i].set_xlabel('Dimensionality Reduction Fraction', fontsize=12)\n",
    "\n",
    "    axes[i].set_ylim(0.75, 1.01)\n",
    "for ax in axes:\n",
    "    ax.legend(ncol=2)\n",
    "    ax.axhline(1, color='black', linestyle='dashed')\n",
    "    \n",
    "fig.suptitle('Neural Network Fluid Parameter Reconstruction Quality', fontweight='bold', fontsize=18)\n",
    "fig.tight_layout()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e363a-1319-4cf8-a0be-ec1f0efb28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['txx', 'tyy', 'tzz']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex='all', sharey='all', figsize=(15, 4), dpi=300)\n",
    "\n",
    "for file_name in [files[1]]:\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "    r2 = {m: hdf[m]['r2'][:] for m in moments}\n",
    "    points_true = {m: hdf[m]['points_true'][:] for m in moments}\n",
    "    points_recon = {m: hdf[m]['points_recon'][:] for m in moments}\n",
    "    hdf.close()\n",
    "    \n",
    "    region_title = 'Phase ' + os.path.basename(os.path.dirname(file_name)).replace(\"_\", \" \").split(\".\")[0]\n",
    "    region_title = ' '.join([word[0].upper() + word[1:] for word in region_title.split(' ')])\n",
    "\n",
    "    for i, m in enumerate(r2):\n",
    "        axes[i].plot(sizes/(32*16*2), r2[m], 'o-')\n",
    "        axes[i].set_title('$'+m[0].capitalize() + '_{' + m[1:]+'}$')\n",
    "        axes[i].set_ylabel('Correlation Coefficient ($r^2$)', fontsize=12)\n",
    "        axes[i].set_xlabel('Dimensionality Reduction Fraction', fontsize=12)\n",
    "\n",
    "    axes[i].set_ylim(0.75, 1.01)\n",
    "for ax in axes:\n",
    "    ax.legend(ncol=2)\n",
    "    ax.axhline(1, color='black', linestyle='dashed')\n",
    "    \n",
    "#fig.suptitle('Neural Network Bulk Velocity Reconstruction Correlation', fontweight='bold', fontsize=18)\n",
    "fig.tight_layout()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac16c5-e27a-4b3d-9a8e-0825eef1036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = ['n']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, sharex='all', sharey='all', figsize=(15, 4), dpi=300)\n",
    "\n",
    "for file_name in [files[1]]:\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "    r2 = {m: hdf[m]['r2'][:] for m in moments}\n",
    "    points_true = {m: hdf[m]['points_true'][:] for m in moments}\n",
    "    points_recon = {m: hdf[m]['points_recon'][:] for m in moments}\n",
    "    hdf.close()\n",
    "    \n",
    "    region_title = 'Phase ' + os.path.basename(os.path.dirname(file_name)).replace(\"_\", \" \").split(\".\")[0]\n",
    "    region_title = ' '.join([word[0].upper() + word[1:] for word in region_title.split(' ')])\n",
    "\n",
    "    for i, m in enumerate(r2):\n",
    "        axes[i].plot(sizes/(32*16*2), r2[m], 'o-')\n",
    "        axes[i].set_title(r'$\\rho$')\n",
    "        axes[i].set_ylabel('Correlation Coefficient ($r^2$)', fontsize=12)\n",
    "        axes[i].set_xlabel('Dimensionality Reduction Fraction', fontsize=12)\n",
    "\n",
    "    axes[i].set_ylim(0.75, 1.01)\n",
    "for ax in axes[:1]:\n",
    "    ax.legend(ncol=2)\n",
    "    ax.axhline(1, color='black', linestyle='dashed')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "#fig.suptitle('Neural Network Bulk Velocity Reconstruction Correlation', fontweight='bold', fontsize=18)\n",
    "fig.tight_layout()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2651aceb-0003-4753-bb3b-1cfdb7cdf544",
   "metadata": {},
   "source": [
    "# Figure 1 - Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c72636-62bd-4599-a027-b1742df83d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(file_name, xlim=None, redline=100, ylim=None, facecolor=None):\n",
    "    # Load data ------------------------------------------\n",
    "    hdf = h5py.File(file_name, 'r')\n",
    "    sizes = hdf['sizes'][:]\n",
    "#    moments = ['n', 'vx', 'vy', 'vz', 'txx', 'tyy', 'tzz', 'txz', 'tyz', 'txy']\n",
    "    moments = ['n', 'vx', 'vy', 'vz', 'txx', 'tyy', 'tzz']\n",
    "\n",
    "    r2 = {m: hdf[m]['r2'] for m in moments}\n",
    "    points_true = {m: hdf[m]['points_true'][:] for m in moments}\n",
    "    points_recon = {m: hdf[m]['points_recon'][:] for m in moments}\n",
    "    #test_data = nnet_evaluate.load_test_data('4B_dayside')\n",
    "    \n",
    "    # Make plot -----------------------------------------\n",
    "    fig, axes = plt.subplots(1, 7, sharex='all', sharey='all', figsize=(20, 3), facecolor=facecolor)\n",
    "    axes_orig = axes\n",
    "    axes = axes.flatten()\n",
    "    for i, m in enumerate(r2):\n",
    "        axes[i].plot(sizes/(32*16*2), r2[m], 'o-')\n",
    "        \n",
    "        if m[0] == 't':\n",
    "            axes[i].set_title(m[0].upper() + m[1:], fontsize=15)\n",
    "        else:\n",
    "            axes[i].set_title(m, fontsize=15)\n",
    "        #axes[i].axvline(1, color='red', linestyle='dashed', label='No Reduction')\n",
    "        #axes[i].axhline(1, color='black', linestyle='dashed')\n",
    "\n",
    "        if xlim:\n",
    "            axes[i].set_xlim(*xlim)\n",
    "        if ylim:\n",
    "            axes[i].set_ylim(*ylim)\n",
    "        axes[i].set_xlabel('Dimensionality Reduction\\n(Fraction)', fontsize=12)\n",
    "        \n",
    "    axes[0].set_ylabel('$r^2$', fontsize=15)\n",
    "    \n",
    "    fig.suptitle(f'Moments Reconstruction vs Dimensionality Reduction Fraction (MMS Mission {region_title})', fontsize=20, fontweight='bold')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64179e2-d41e-42ad-a0a8-fa50a5301f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/all.rfr001/moments_stats.hdf', ylim=(.75, 1.05), facecolor='#fffee0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa675e-1010-4482-ac26-d0956774f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4A_dusk_flank.rfr001/moments_stats.hdf', ylim=(.75, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860da82-c4f2-4876-8f61-f96fa1dd41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4B_dayside.rfr001/moments_stats.hdf', ylim=(.75, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5c2a9-c804-4b18-8e30-a4f68f0674e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4C_dawn_flank.rfr001/moments_stats.hdf', ylim=(.75, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3b5de-60b1-456b-827a-1b72825a4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('/mnt/efs/dasilva/compression-cfha/data/nnet_models/hidden_layer_exp/4D_tail.rfr001/moments_stats.hdf', ylim=(.75, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb6336-d175-44a3-a76f-66173cae87bb",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4817c41-5238-4a45-91c0-835954cde5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(cdf_filename):\n",
    "\n",
    "    N_EN = 32\n",
    "    N_EN_SHELLS = 2\n",
    "    N_PHI = 32\n",
    "    N_THETA = 16\n",
    "    cdf = pycdf.CDF(cdf_filename)\n",
    "\n",
    "    dist = cdf['mms1_dis_dist_brst'][:]\n",
    "    dist_err = cdf['mms1_dis_disterr_brst'][:]\n",
    "    epoch = cdf['Epoch'][:]\n",
    "    ntime = epoch.size\n",
    "    counts = np.zeros((ntime, N_PHI, N_THETA, N_PHI))\n",
    "\n",
    "    for i in range(ntime):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore')\n",
    "            tmp_counts = np.square(dist[i] / dist_err[i])\n",
    "        tmp_counts[np.isnan(tmp_counts)] = 0\n",
    "        tmp_counts = np.rint(tmp_counts)\n",
    "        counts[i] = tmp_counts\n",
    "\n",
    "    cdf.close()\n",
    "\n",
    "    return epoch, counts, ntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22b87f-7bd9-4c64-9b06-ff68b528682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = nnet_evaluate.load_test_data('4B_dayside')\n",
    "f1ct = utils.get_f1ct({'4B_dayside': test_data}, ['4B_dayside'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b66be-3c2b-427e-966c-1efcc13ab170",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.array([2.160000e+00, 3.910000e+00, 7.070000e+00, 1.093000e+01,\n",
    "       1.424000e+01, 1.854000e+01, 2.414000e+01, 3.144000e+01,\n",
    "       4.094000e+01, 5.332000e+01, 6.944000e+01, 9.043000e+01,\n",
    "       1.177700e+02, 1.533600e+02, 1.997200e+02, 2.601000e+02,\n",
    "       3.387200e+02, 4.411100e+02, 5.744500e+02, 7.481000e+02,\n",
    "       9.742300e+02, 1.268720e+03, 1.652240e+03, 2.151680e+03,\n",
    "       2.802100e+03, 3.649120e+03, 4.752190e+03, 6.188690e+03,\n",
    "       8.059430e+03, 1.049565e+04, 1.366831e+04, 1.780000e+04],\n",
    "      dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d042e5-4927-450a-9b38-667a0a10e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EN = 32\n",
    "N_EN_SHELLS = 2\n",
    "N_PHI = 32\n",
    "N_THETA = 16\n",
    "\n",
    "hdf_filename = glob.glob('/home/ubuntu/data/recons/4B_dayside-100/*.hdf5')[95]\n",
    "print(hdf_filename)\n",
    "cdf_filename = '/mnt/efs/dasilva/compression-cfha/data/mms_data/4B_dayside/' + os.path.basename(hdf_filename).replace('.hdf5', '.cdf')\n",
    "gpc_filename = hdf_filename.replace('.hdf5', '.gpc')\n",
    "\n",
    "epoch, counts, ntime = get_data(cdf_filename)\n",
    "\n",
    "hdf = h5py.File(hdf_filename, 'r')\n",
    "counts_recon = hdf['counts'][:]\n",
    "hdf.close()\n",
    "\n",
    "moms_true = [moms_fast.fast_moments(f1ct * c) for c in counts]\n",
    "moms_recon = [moms_fast.fast_moments(f1ct * c) for c in counts_recon]\n",
    "\n",
    "\n",
    "cmpr_ratio =  (32 * 16 * 32 * 16 * epoch.size) / (os.path.getsize(gpc_filename) * 8)\n",
    "file_size = os.path.getsize(gpc_filename) / epoch.size\n",
    "vars = ['Strue', 'Srecon']\n",
    "fig, axes = plt.subplots(len(vars), 1, figsize=(15, 4*len(vars)))\n",
    "\n",
    "\n",
    "Escale = np.zeros((32, counts.shape[0]))\n",
    "for k in range(Escale.shape[1]):\n",
    "    Escale[:, k] = E\n",
    "\n",
    "for i, var in enumerate(vars):\n",
    "    vmin = .01\n",
    "    vmax = 15\n",
    "    if var == 'Strue':\n",
    "        im = axes[i].pcolor(epoch, E, (counts).mean(axis=((1, 2))).T, norm=LogNorm(vmin=vmin, vmax=vmax), cmap='jet')\n",
    "        axes[i].set_ylabel('$\\\\bf{Original~Ion~Data}$\\nEnergy [eV]', fontsize=18)\n",
    "    elif var == 'Srecon':\n",
    "        im = axes[i].pcolor(epoch, E, (counts_recon).mean(axis=((1, 2))).T, norm=LogNorm(vmin=vmin, vmax=vmax), cmap='jet')\n",
    "        axes[i].set_ylabel('$\\\\bf{Compressed~Ion~Data}$\\nEnergy [eV]', fontsize=18)\n",
    "    \n",
    "    axes[i].set_yscale('log')\n",
    "    divider = make_axes_locatable(axes[i])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical').set_label('Average Counts\\nper Energy Channel', fontsize=16)\n",
    "\n",
    "axes[0].set_title(f'Demonstration of Compression (Compression Ratio: {cmpr_ratio:.1f}X)', fontweight='bold', fontsize=20)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f91a5f-896c-4c39-bead-7ffcda6719d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430c577-1ddb-4446-8510-87828250d516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Compression-CFHA",
   "language": "python",
   "name": "compression-cfha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
